close file...
close file...





Loading checkpoint shards: 100%|██████████| 6/6 [00:19<00:00,  3.22s/it]
  0%|          | 0/654 [00:00<?, ?it/s]/home/xchen/.conda/envs/blip2022/lib/python3.8/site-packages/transformers/generation/utils.py:1349: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(




































































































































 99%|█████████▉| 650/654 [04:27<00:01,  2.35it/s]
Performance: {'cls_acc': 59.07, 'y_f1_score': 70.84, 'y_precision': 55.02, 'y_recall': 99.44, 'n_f1_score': 31.37, 'n_precision': 97.07, 'n_recall': 18.71, 'total': 2480, 'num_yes': 2241, 'num_no': 239}
2241

100%|██████████| 654/654 [04:29<00:00,  2.43it/s]