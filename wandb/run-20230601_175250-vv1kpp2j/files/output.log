
close file...





Loading checkpoint shards: 100%|██████████| 6/6 [00:18<00:00,  3.14s/it]
  0%|          | 0/613 [00:00<?, ?it/s]/home/xchen/.conda/envs/blip2022/lib/python3.8/site-packages/transformers/generation/utils.py:1349: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(




























































































































100%|█████████▉| 611/613 [04:11<00:00,  2.47it/s]
Accuracy: 0.0
1037

100%|██████████| 613/613 [04:12<00:00,  2.43it/s]